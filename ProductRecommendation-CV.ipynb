{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITEM BASED COLLABORATIVE FILTERING - IBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from jproperties import Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIV123                            0.140681\n",
      "DM_P2                             0.117106\n",
      "AB_CCARDS                         0.076253\n",
      "AB_CWN                            0.052254\n",
      "AB_AMF                            0.048927\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class ProdReco:\n",
    "    \n",
    "    def evaluation(self,csv_file_path):\n",
    "#Read the csv File\n",
    "df = pd.read_csv('C:/Users/reraveen/Jupyter/Dataset/ORMB_Data_version.csv',na_values ='')\n",
    "dfprocessed =df.groupby(['PERSON_ID', 'PRICEITEM_CD']).size().reset_index().rename(columns={0:'Score'})\n",
    "train=dfprocessed.sample(frac=0.60,random_state=123) #random state is a seed value\n",
    "test_Actual=dfprocessed.drop(train.index)\n",
    "print(train.shape)\n",
    "test = test_Actual.copy()\n",
    "print(test.shape)\n",
    "#Convert already bought product score to 0 for testing purpose\n",
    "test.loc[:, 'Score'] =0\n",
    "testDataset = pd.concat([train,test], ignore_index=True)\n",
    "print(testDataset.shape)\n",
    "TableCustItem =testDataset.pivot(index='PERSON_ID', columns='PRICEITEM_CD', values='Score')\n",
    "TableCustItem =TableCustItem.replace(np.nan,0)\n",
    "print(TableCustItem.shape)\n",
    "\n",
    "df_crossTabedold = pd.crosstab(df.PERSON_ID, df.PRICEITEM_CD).reset_index().rename_axis('',axis='columns') \n",
    "df_crossTabedold.shape\n",
    "TableCustItem =TableCustItem.merge(df_crossTabedold[\"PERSON_ID\"], on='PERSON_ID', how='left')\n",
    "df_crossTabed=TableCustItem\n",
    "df_crossTabed1 = df_crossTabed.drop('PERSON_ID', 1)\n",
    "df_crossTabed1.head()\n",
    "df_crossTabed1.shape\n",
    "\n",
    "magnitude = np.sqrt(np.square(df_crossTabed1).sum(axis=1))\n",
    "df_crossTabed2 = df_crossTabed1.divide(magnitude, axis='index')\n",
    "df_crossTabed2 =df_crossTabed2.replace(np.nan,0)\n",
    "\n",
    "def calculate_similarity(data_items):\n",
    "    \"\"\"Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix. Return a new dataframe matrix with similarities.\n",
    "    \"\"\"\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    sim = pd.DataFrame(data=similarities, index= data_items.columns, columns= data_items.columns)\n",
    "    return sim\n",
    "\n",
    "data_matrix = calculate_similarity(df_crossTabed2)\n",
    "data_matrix=data_matrix.replace(np.nan,0)\n",
    "scoredf = data_matrix.dot(df_crossTabed2.T)\n",
    "scoredf =scoredf.T\n",
    "scoredf=scoredf.div(data_matrix.sum(axis=1))\n",
    "scoredf=scoredf.replace(np.nan,0)\n",
    "Bought_df=df_crossTabed2.where(df_crossTabed2==0,-999999)\n",
    "recommd_df=Bought_df.where(Bought_df != 0,scoredf)\n",
    "top_n = 7\n",
    "df_final = pd.DataFrame({n: recommd_df.T[col].nlargest(top_n).index.tolist() \n",
    "                for n, col in enumerate(recommd_df.T)}).T\n",
    "\n",
    "new_col =df_crossTabed['PERSON_ID']\n",
    "df_final.insert(0,'PERSON_ID',new_col,True)\n",
    "df_final\n",
    "\n",
    "test_Actual_cross = pd.crosstab(test_Actual.PERSON_ID, test_Actual.PRICEITEM_CD).reset_index().rename_axis('',axis='columns') \n",
    "test_Actual_cross\n",
    "\n",
    "testPersonId=test_Actual_cross['PERSON_ID']\n",
    "test_Actual_cross=test_Actual_cross.drop(['PERSON_ID'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "test_Actual_cross_df=test_Actual_cross.where(test_Actual_cross==0,-999999)\n",
    "test_Actual_cross_df\n",
    "\n",
    "Actual_BoughtList = (test_Actual_cross_df == -999999).sum(axis=1)\n",
    "Actual_BoughtList\n",
    "\n",
    "top_n = 7\n",
    "Test_final = pd.DataFrame({n:test_Actual_cross.T[col].nlargest(top_n).index.tolist() \n",
    "                for n, col in enumerate(test_Actual_cross.T)}).T\n",
    "\n",
    "Test_final.insert(0,'PERSON_ID',testPersonId,True)\n",
    "MeredDf = Test_final.merge(df_final, on=\"PERSON_ID\", how = 'inner')\n",
    "MeredDf_Selected = MeredDf.loc[:,MeredDf.columns != 'PERSON_ID']\n",
    "MeredDf['num_uniq'] = [len(set(v[pd.notna(v)].tolist())) for v in MeredDf_Selected.values]\n",
    "MeredDf['num_uniq']=14-MeredDf['num_uniq']\n",
    "MeredDf['precision']=MeredDf['num_uniq']/7\n",
    "meanprecision = MeredDf['precision'].mean()\n",
    "print(\"Precision :\"+str(meanprecision))\n",
    "rowCount =len(Test_final.index)\n",
    "MeredDf['ActualBought']=Actual_BoughtList\n",
    "actalBoughtCommon=[]\n",
    "for j in range(0,rowCount):\n",
    "    elements=[]\n",
    "    actalCommon=0\n",
    "    actualBought = Actual_BoughtList[j]\n",
    "    eval_Value =7\n",
    "    startindex = 7+1\n",
    "    endInx =eval_Value*2+1\n",
    "    elements.extend(Test_final.iloc[j,1:actualBought+1])\n",
    "    elements.extend(MeredDf.iloc[j,startindex:endInx])\n",
    "    a_set = set(elements)\n",
    "    number_unique = len(a_set)\n",
    "    actalCommon = (actualBought+eval_Value)-number_unique\n",
    "    actalBoughtCommon.append(actalCommon)\n",
    "actalBoughtCommon\n",
    "\n",
    "MeredDf['ActualBoughtPredicted']=actalBoughtCommon\n",
    "MeredDf['Recall']=MeredDf['ActualBoughtPredicted']/MeredDf['num_uniq']\n",
    "meanrecall=MeredDf['Recall'].mean()\n",
    "print(\"Recall :\"+str(meanrecall))\n",
    "mean_f1score = 2*(meanrecall*meanprecision)/(meanrecall+meanprecision)\n",
    "print(\"F1-Score:\"+str(mean_f1score))\n",
    "        \n",
    "    \n",
    "    def recommend_building(self,csv_file_path):\n",
    "        #Item-Item similarity function\n",
    "        def calculate_similarity(data_items):\n",
    "            \"\"\"Calculate the column-wise cosine similarity for a sparse\n",
    "            matrix. Return a new dataframe matrix with similarities.\n",
    "            \"\"\"\n",
    "            data_sparse = sparse.csr_matrix(data_items)\n",
    "            similarities = cosine_similarity(data_sparse.transpose())\n",
    "            sim = pd.DataFrame(data=similarities, index= data_items.columns, columns= data_items.columns)\n",
    "            return sim\n",
    "\n",
    "        #Read the csv File\n",
    "        df = pd.read_csv(csv_file_path,na_values ='')\n",
    "        #A matrix repersentation of Person x Products\n",
    "        df_crossTabed = pd.crosstab(df.PERSON_ID, df.PRICEITEM_CD).reset_index().rename_axis('',axis='columns') \n",
    "        df_crossTabed1 = df_crossTabed.drop('PERSON_ID', 1)\n",
    "        #Normalizing the values\n",
    "        magnitude = np.sqrt(np.square(df_crossTabed1).sum(axis=1))\n",
    "        df_crossTabed2 = df_crossTabed1.divide(magnitude, axis='index')\n",
    "        #Calling the similarity Function for Item-Item Matrix\n",
    "        data_matrix = calculate_similarity(df_crossTabed2)\n",
    "        #Changing the datatype of Person_Id to str\n",
    "        df_crossTabed['PERSON_ID'] = df_crossTabed.PERSON_ID.astype(str)\n",
    "        data_items = df_crossTabed.drop('PERSON_ID', 1)\n",
    "        data_items2 = data_items.divide(magnitude, axis='index')\n",
    "        score = data_matrix.dot(data_items2.T)\n",
    "        score =score.T\n",
    "        score=score.div(data_matrix.sum(axis=1))\n",
    "        bought_df=data_items2.where(data_items2==0,-999999)\n",
    "        recommd_df=bought_df.where(bought_df != 0,score)\n",
    "        new_col =df_crossTabed['PERSON_ID']\n",
    "        recommd_df.insert(0,'PERSON_ID',new_col,True)\n",
    "        #recommd_df -have to save in a table/datastore\n",
    "        recommd_df.to_json(\"recommendation1.JSON\",orient=\"columns\")\n",
    "        \n",
    "\n",
    "\n",
    "    #Recommendation Function\n",
    "    def recommended_execution(self,customer_no,no_products):\n",
    "        recommd_df = pd.read_json(r'recommendation1.JSON')\n",
    "        recommd_df['PERSON_ID'] = recommd_df.PERSON_ID.astype(str)\n",
    "        data_items = recommd_df.drop('PERSON_ID', 1)\n",
    "        user_index = recommd_df[recommd_df.PERSON_ID == customer_no].index.tolist()[0]\n",
    "        rating = data_items.loc[user_index] \n",
    "        recommend_products=rating.nlargest(no_products)\n",
    "        return  recommend_products\n",
    "\n",
    "#Initialize the object for class prodReco\n",
    "product_reco_object = ProdReco()\n",
    "#get the configuration for the input dataset\n",
    "configs = Properties()\n",
    "with open('config.properties', 'rb') as config_file:\n",
    "    configs.load(config_file)\n",
    "csv_file_path = configs[\"filePath\"].data\n",
    "product_reco_object.recommend_building(csv_file_path)\n",
    "product_reco_object.evaluation(csv_file_path)\n",
    "#Recommendation for given CustomerNo=72231957, and the number of products to recommend as Nproducts=5\n",
    "recommed_products= product_reco_object.recommended_execution('72231957',5)\n",
    "print(recommed_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
