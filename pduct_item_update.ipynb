{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 25)\n",
      "(27, 3)\n",
      "(27, 3)\n",
      "                      PRICEITEM_CD                      PRODUCT_CD  \\\n",
      "0   AB_AMF                          APPTEST2                         \n",
      "1   AB_AMF                          BTA                              \n",
      "2   AB_AMF                          BTA1                             \n",
      "3   AB_AOF                          APPTEST2                         \n",
      "4   AB_AOF                          BTA                              \n",
      "5   AB_AOF                          BTA1                             \n",
      "6   AB_CCARDS                       BTA                              \n",
      "7   AB_CCARDS                       BTA1                             \n",
      "8   AB_CWN                          APPTEST2                         \n",
      "9   AB_CWN                          BTA                              \n",
      "10  AB_CWN                          BTA1                             \n",
      "11  ACHCR                           ABC_BNK_STD_PROD                 \n",
      "12  ACHDR                           ABC_BNK_STD_PROD                 \n",
      "13  ACHPIF                          PAYMENT_US                       \n",
      "14  ACHRET                          PAYMENT_US                       \n",
      "15  ACHREV                          PAYMENT_US                       \n",
      "16  CDMF                            ABC_BNK_STD_PROD                 \n",
      "17  CDOTC                           ABC_BNK_STD_PROD                 \n",
      "18  CDPTF                           ABC_BNK_STD_PROD                 \n",
      "19  CHQBK                           CURRENT_PRD                      \n",
      "20  IBDWT                           PAYMENT_US                       \n",
      "21  LMF                             ABC_BNK_STD_PROD                 \n",
      "22  LTF                             ABC_BNK_STD_PROD                 \n",
      "23  OBIF                            PAYMENT_US                       \n",
      "24  ONDWT                           PAYMENT_US                       \n",
      "25  PLM_PI                          PLM                              \n",
      "26  TFR                             CURRENT_PRD                      \n",
      "\n",
      "    ITEM_OCCURANCE  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "5                1  \n",
      "6                1  \n",
      "7                1  \n",
      "8                1  \n",
      "9                1  \n",
      "10               1  \n",
      "11               1  \n",
      "12               1  \n",
      "13               1  \n",
      "14               1  \n",
      "15               1  \n",
      "16               1  \n",
      "17               1  \n",
      "18               1  \n",
      "19               3  \n",
      "20               1  \n",
      "21               1  \n",
      "22               1  \n",
      "23               1  \n",
      "24               1  \n",
      "25               1  \n",
      "26               3  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Too many levels: Index has only 1 level, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-eec22586fa3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[0mobjectProductReco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProdReco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjectProductReco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m \u001b[0mobjectProductReco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommendation_building\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[0mobjectProductReco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;31m# Recommendation for given customer_no=72231957, and the number of products to recommend as no_products=5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-eec22586fa3a>\u001b[0m in \u001b[0;36mrecommendation_building\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mrecommend_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PERSON_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m#recommend_df=recommend_df.append(item_product_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mrecommend_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecommend_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_product_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommend_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m#path = \"~/recommendation1.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reraveen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[1;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[0;32m   4813\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4814\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4815\u001b[1;33m             \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlev\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4816\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4817\u001b[0m                 \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdroplevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reraveen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4813\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4814\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4815\u001b[1;33m             \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlev\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4816\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4817\u001b[0m                 \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdroplevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reraveen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_level_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_index_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reraveen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_validate_index_level\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   1400\u001b[0m                 )\n\u001b[0;32m   1401\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1402\u001b[1;33m                 raise IndexError(\n\u001b[0m\u001b[0;32m   1403\u001b[0m                     \u001b[1;34mf\"Too many levels: Index has only 1 level, not {level + 1}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m                 )\n",
      "\u001b[1;31mIndexError\u001b[0m: Too many levels: Index has only 1 level, not 2"
     ]
    }
   ],
   "source": [
    "# ITEM BASED COLLABORATIVE FILTERING - IBCF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from jproperties import Properties\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def calculate_similarity(data_items):\n",
    "    \"\"\"Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix. Return a new dataframe matrix with similarities.\n",
    "    :param :data_items\n",
    "    \"\"\"\n",
    "\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    similarity_data = pd.DataFrame(data=similarities, index=data_items.columns, columns=data_items.columns)\n",
    "    return similarity_data\n",
    "\n",
    "\n",
    "class ProdReco:\n",
    "    def __init__(self, csv_path):\n",
    "        self.dataset = pd.read_csv(csv_path, na_values='')\n",
    "\n",
    "    def recommendation_building(self):\n",
    "        \"\"\"Calculate the recommendation for each customer\n",
    "        . Saving the result dataframe in json file.\n",
    "             \"\"\"\n",
    "        data = self.dataset\n",
    "        dfcross_tabed = pd.crosstab(data.PERSON_ID, data.PRICEITEM_CD).reset_index().rename_axis('', axis='columns')\n",
    "        dfcross_tabed1 = dfcross_tabed.drop('PERSON_ID', 1)\n",
    "        item_product_data=data.groupby(['PRICEITEM_CD', 'PRODUCT_CD']).size().reset_index().rename(columns={0:'ITEM_OCCURANCE'})\n",
    "        \n",
    "        print(item_product_data.shape)\n",
    "        item_product_data=item_product_data.dropna()\n",
    "        print(item_product_data.shape)\n",
    "        print(item_product_data)\n",
    "        \n",
    "        # Normalizing the values\n",
    "        magnitude = np.sqrt(np.square(dfcross_tabed1).sum(axis=1))\n",
    "        dfcross_tabed2 = dfcross_tabed1.divide(magnitude, axis='index')\n",
    "        # Calling the similarity Function for Item-Item Matrix\n",
    "        data_matrix = calculate_similarity(dfcross_tabed2)\n",
    "        # Changing the datatype of Person_Id to str\n",
    "        dfcross_tabed['PERSON_ID'] = dfcross_tabed.PERSON_ID.astype(str)\n",
    "        data_items = dfcross_tabed.drop('PERSON_ID', 1)\n",
    "        data_items2 = data_items.divide(magnitude, axis='index')\n",
    "        scoredata = data_matrix.dot(data_items2.T)\n",
    "        scoredata = scoredata.T\n",
    "        scoredata = scoredata.div(data_matrix.sum(axis=1))\n",
    "        bought_df = data_items2.where(data_items2 == 0, -999999)\n",
    "        recommend_df = bought_df.where(bought_df != 0, scoredata)\n",
    "        new_col = dfcross_tabed['PERSON_ID']\n",
    "        recommend_df.insert(0, 'PERSON_ID', new_col, True)\n",
    "        #recommend_df=recommend_df.append(item_product_data)\n",
    "        recommend_df = pd.concat([recommend_df, item_product_data], axis=1, ignore_index=True).reset_index(drop=True, level=1)\n",
    "        print(recommend_df)\n",
    "        #path = \"~/recommendation1.json\"\n",
    "        #full_path = os.path.expanduser(path)\n",
    "        #print(full_path)\n",
    "        #item_product_data.to_json(\"recommendation1.json\", orient=\"columns\")\n",
    "        # recommd_df -have to save in a table/datastore\n",
    "        recommend_df.to_json(\"recommendation1.json\", orient=\"columns\")\n",
    "        print(recommend_df)\n",
    "    def evaluation(self):\n",
    "        \"\"\"Finding the Evaluation Parameters for the recommendation system\n",
    "        \"\"\"\n",
    "        # Read the csv File\n",
    "        df = self.dataset\n",
    "        dfprocessed = df.groupby(['PERSON_ID', 'PRICEITEM_CD']).size().reset_index().rename(columns={0: 'Score'})\n",
    "        train = dfprocessed.sample(frac=0.70, random_state=123)  # random state is a seed value\n",
    "        test_actual = dfprocessed.drop(train.index)\n",
    "        test = test_actual.copy()\n",
    "        # Convert already bought product count/score to 0 for testing purpose\n",
    "        test.loc[:, 'Score'] = 0\n",
    "        testdataset = pd.concat([train, test], ignore_index=True)\n",
    "        custitemtable = testdataset.pivot(index='PERSON_ID', columns='PRICEITEM_CD', values='Score')\n",
    "        custitemtable = custitemtable.replace(np.nan, 0)\n",
    "        crosstableold = pd.crosstab(df.PERSON_ID, df.PRICEITEM_CD).reset_index().rename_axis('', axis='columns')\n",
    "        custitemtable = custitemtable.merge(crosstableold[\"PERSON_ID\"], on='PERSON_ID', how='left')\n",
    "        df_cross_tabed1 = custitemtable.drop('PERSON_ID', 1)\n",
    "        magnitude = np.sqrt(np.square(df_cross_tabed1).sum(axis=1))\n",
    "        df_cross_tabed2 = df_cross_tabed1.divide(magnitude, axis='index')\n",
    "        df_cross_tabed2 = df_cross_tabed2.replace(np.nan, 0)\n",
    "        data_matrix = calculate_similarity(df_cross_tabed2)\n",
    "        data_matrix = data_matrix.replace(np.nan, 0)\n",
    "        scoredf = data_matrix.dot(df_cross_tabed2.T)\n",
    "        scoredf = scoredf.T\n",
    "        scoredf = scoredf.div(data_matrix.sum(axis=1))\n",
    "        scoredf = scoredf.replace(np.nan, 0)\n",
    "        bought_df = df_cross_tabed2.where(df_cross_tabed2 == 0, -999999)\n",
    "        recommd_df = bought_df.where(bought_df != 0, scoredf)\n",
    "        evalconstant = 2\n",
    "        evaluation_metrices = {}\n",
    "        df_final = pd.DataFrame({n: recommd_df.T[col].nlargest(evalconstant).index.tolist()\n",
    "                                 for n, col in enumerate(recommd_df.T)}).T\n",
    "\n",
    "        new_col = custitemtable['PERSON_ID']\n",
    "        df_final.insert(0, 'PERSON_ID', new_col, True)\n",
    "        test_actual_cross = pd.crosstab(test_actual.PERSON_ID, test_actual.PRICEITEM_CD).reset_index().rename_axis('',\n",
    "                                                                                                                   axis='columns')\n",
    "        test_person_id = test_actual_cross['PERSON_ID']\n",
    "        test_actual_cross = test_actual_cross.drop(['PERSON_ID'], axis=1)\n",
    "        test_actual_cross_df = test_actual_cross.where(test_actual_cross == 0, -999999)\n",
    "        actual_bought_list = (test_actual_cross_df == -999999).sum(axis=1)\n",
    "        test_final = pd.DataFrame({n: test_actual_cross.T[col].nlargest(evalconstant).index.tolist()\n",
    "                                   for n, col in enumerate(test_actual_cross.T)}).T\n",
    "        test_final.insert(0, 'PERSON_ID', test_person_id, True)\n",
    "        mered_df = test_final.merge(df_final, on=\"PERSON_ID\", how='inner')\n",
    "        mered_df_selected = mered_df.loc[:, mered_df.columns != 'PERSON_ID']\n",
    "        # Calculating the Precision\n",
    "        mered_df['num_uniq'] = [len(set(v[pd.notna(v)].tolist())) for v in mered_df_selected.values]\n",
    "        mered_df['num_uniq'] = (evalconstant * 2) - mered_df['num_uniq']\n",
    "        mered_df['precision'] = mered_df['num_uniq'] / evalconstant\n",
    "        meanprecision = mered_df['precision'].mean()\n",
    "        evaluation_metrices[\"Precision\"] = meanprecision\n",
    "        # Calculating the Recall\n",
    "        row_count = len(test_final.index)\n",
    "        mered_df['ActualBought'] = actual_bought_list\n",
    "        actal_bought_common = []\n",
    "        for loopvar in range(0, row_count):\n",
    "            elements = []\n",
    "            actual_bought = actual_bought_list[loopvar]\n",
    "            startindex = evalconstant + 1\n",
    "            end_index = evalconstant * 2 + 1\n",
    "            elements.extend(test_final.iloc[loopvar, 1:actual_bought + 1])\n",
    "            elements.extend(mered_df.iloc[loopvar, startindex:end_index])\n",
    "            a_set = set(elements)\n",
    "            number_unique = len(a_set)\n",
    "            actal_common = (actual_bought + evalconstant) - number_unique\n",
    "            actal_bought_common.append(actal_common)\n",
    "        mered_df['ActualBoughtPredicted'] = actal_bought_common\n",
    "        mered_df['ActualBought'] = mered_df['ActualBought'].replace(np.nan, 0)\n",
    "        mered_df.loc[mered_df.ActualBought > evalconstant, 'ActualBought'] = evalconstant\n",
    "        mered_df['Recall'] = mered_df['ActualBoughtPredicted'] / mered_df['ActualBought']\n",
    "        mered_df['Recall'] = mered_df['Recall'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        meanrecall = mered_df['Recall'].mean()\n",
    "        evaluation_metrices[\"Recall\"] = meanrecall\n",
    "        mean_f1score = 2 * (meanrecall * meanprecision) / (meanrecall + meanprecision)\n",
    "        evaluation_metrices[\"F1-Score\"] = mean_f1score\n",
    "        print(evaluation_metrices)\n",
    "        return evaluation_metrices\n",
    "\n",
    "    @staticmethod\n",
    "    def recommended_execution(customer_no, no_products):\n",
    "        \"\"\"Give the product recommendation for a customer based on the input .\n",
    "                     \"\"\"\n",
    "        recommd_df = pd.read_json(r'recommendation1.json')\n",
    "        item_product_df['PRICEITEM_CD']=recommd_df.PRICEITEM_CD\n",
    "        item_product_df['PRODUCT_CD']= recommd_df.PRODUCT_CD\n",
    "        recommd_df=recommd_df.drop(['PRICEITEM_CD','PRODUCT_CD','COUNT'],axis =1)\n",
    "        #item_product_df = pd.read_json(r'item_product_mapping.json')\n",
    "        recommd_df['PERSON_ID'] = recommd_df.PERSON_ID.astype(str)\n",
    "        data_items = recommd_df.drop('PERSON_ID', 1)\n",
    "        user_index = recommd_df[recommd_df.PERSON_ID == customer_no].index.tolist()[0]\n",
    "        rating = data_items.loc[user_index]\n",
    "        print(\"----dataitems-------\")\n",
    "        print(data_items)\n",
    "        print(type(rating))\n",
    "        print(rating)\n",
    "        sorted_series = rating.sort_values(ascending=False)\n",
    "        print(sorted_series)\n",
    "        selectd_rows = sorted_series[sorted_series>0]\n",
    "        print(\"-----greater than zeres--------\")\n",
    "        print(selectd_rows)\n",
    "        recommended_item_list =selectd_rows.index\n",
    "        item_product_df =item_product_df.loc[item_product_df['PRICEITEM_CD'].isin(recommended_item_list)]\n",
    "        print(item_product_df)\n",
    "        recommend_products_df =pd.DataFrame()\n",
    "        recommend_products_df['PRICEITEM_CD']=list(selectd_rows.index)\n",
    "        recommend_products_df['SCORE']=list(selectd_rows.values)\n",
    "        merged_data = recommend_products_df.merge(item_product_df, on=\"PRICEITEM_CD\", how = 'left')\n",
    "        print(merged_data)\n",
    "        \n",
    "        \n",
    "        merged_data=merged_data.dropna()\n",
    "        print(merged_data)\n",
    "        print(type(merged_data))\n",
    "        \n",
    "        \n",
    "        \n",
    "        product_series = merged_data['PRODUCT_CD']\n",
    "        sorted_product=product_series.value_counts(normalize=False)\n",
    "        print(sorted_product)\n",
    "        print(type(sorted_product))\n",
    "        d = dict(zip(sorted_product.index,sorted_product.values))\n",
    "        merged_data['COUNT'] = merged_data['PRODUCT_CD'].map(d)\n",
    "        #merged_productcount = merged_data.merge(sorted_product, on=\"PRODUCT_CD\", how = 'left')\n",
    "        print(merged_data)\n",
    "        merged_data['SCORE_UPDATED'] = merged_data['SCORE']*merged_data['COUNT']\n",
    "        print(merged_data)\n",
    "        recommended_products_scoredf = merged_data.sort_values(by = 'SCORE_UPDATED',ascending = False) \n",
    "        print(recommended_products_scoredf)\n",
    "        recommended_products_score_df = recommended_products_scoredf.drop_duplicates(subset=['PRODUCT_CD'], keep='first') \n",
    "        product_data = recommended_products_score_df.drop(['PRICEITEM_CD','SCORE','COUNT'],axis =1)\n",
    "        #print(product_data)\n",
    "        \n",
    "        if len(product_data)+1 <= no_products:\n",
    "            print(\"reduce recommendation input\")\n",
    "            recommend_products_series=None\n",
    "        else:\n",
    "            recommend_products_series =product_data.head(no_products)\n",
    "            print(recommend_products_series)\n",
    "            \n",
    "        #recommend_products_series = rating.nlargest(no_products)\n",
    "        #print(recommend_products_series)\n",
    "        #recommended_item_list =recommend_products_series.index\n",
    "        #item_product_df =item_product_df.loc[item_product_df['PRICEITEM_CD'].isin(recommended_item_list)]\n",
    "        #print(item_product_df)\n",
    "        #recommend_products_df =pd.DataFrame()\n",
    "        #recommend_products_df['PRICEITEM_CD']=list(recommend_products_series.index)\n",
    "        #recommend_products_df['SCORE']=list(recommend_products_series.values)\n",
    "        #merged_data = recommend_products_df.merge(item_product_df, on=\"PRICEITEM_CD\", how = 'left')\n",
    "        #print(merged_data)\n",
    "        #product_series = item_product_df['PRODUCT_CD']\n",
    "        #sorted_product=product_series.value_counts(normalize=False)\n",
    "        #sorted_product =.value_counts(product_series, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
    "        #recommended_products_scoredf = merged_data.groupby('PRODUCT_CD')['SCORE'].max().reset_index()\n",
    "        #recommended_products_scoredf = recommended_products_scoredf.sort_values(by = 'SCORE',ascending = False) \n",
    "        #print(recommended_products_scoredf)\n",
    "        #print(recommend_products_series.iloc[0])\n",
    "        #print(sorted_product)\n",
    "        return recommend_products_series\n",
    "\n",
    "\n",
    "configs = Properties()\n",
    "with open('config.properties', 'rb') as config_file:\n",
    "    configs.load(config_file)\n",
    "csvfilepath = configs[\"filePath\"].data\n",
    "objectProductReco = ProdReco(csvfilepath)\n",
    "print(objectProductReco.dataset.shape)\n",
    "objectProductReco.recommendation_building()\n",
    "objectProductReco.evaluation()\n",
    "# Recommendation for given customer_no=72231957, and the number of products to recommend as no_products=5\n",
    "recommend_products = objectProductReco.recommended_execution('72231957', 6)\n",
    "#print(recommend_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC_BNK_STD_PROD  7\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
